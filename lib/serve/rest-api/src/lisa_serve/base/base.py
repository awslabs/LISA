#   Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
#   Licensed under the Apache License, Version 2.0 (the "License").
#   You may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.

"""Base model adapters and responses."""
import re
from abc import ABC, abstractmethod
from typing import Any, AsyncGenerator, Dict, List, Optional

from pydantic import BaseModel, Field

#############
# RESPONSES #
#############


class EmbedQueryResponse(BaseModel):
    """Response for embed_query method."""

    embeddings: List[List[float]] = Field(..., description="Batch of text embeddings.")


class GenerateResponse(BaseModel):
    """Response for generate method."""

    generatedText: str = Field(..., description="Generated text.")
    generatedTokens: Optional[int] = Field(..., description="Number of generated tokens.")
    finishReason: Optional[str] = Field(None, description="Reason for finishing text generation.")


class Token(BaseModel):
    """Token for generate_stream method."""

    text: str = Field(..., description="Token text.")
    special: Optional[bool] = Field(None, description="Whether token is a special token.")


class GenerateStreamResponse(BaseModel):
    """Response for generate_stream method."""

    token: Token
    generatedTokens: Optional[int] = Field(..., description="Number of generated tokens.")
    finishReason: Optional[str] = Field(None, description="Reason for finishing text generation.")


class OpenAIChatCompletionsDelta(BaseModel):
    """Token content from Chat Completions endpoint."""

    content: str = Field(..., description="The contents of the chunk message.")
    role: str = Field(..., description="The role of the author of this message.")


class OpenAIChatCompletionsChoice(BaseModel):
    """Text choice object from Chat Completions endpoint."""

    delta: OpenAIChatCompletionsDelta = Field(
        ..., description="A chat completion delta generated by streamed model responses."
    )
    finish_reason: Optional[str] = Field(..., description="The reason the model stopped generating tokens.")
    index: int = Field(..., description="The index of the choice in the list of choices.")


class OpenAIChatCompletionsResponse(BaseModel):
    """Response from Chat Completions endpoint."""

    id: str = Field(..., description="A unique identifier for the chat completion. Each chunk has the same ID.")
    choices: list[OpenAIChatCompletionsChoice] = Field(
        ..., description="A list of chat completion choices. Can be more than one if n is greater than 1."
    )
    created: int = Field(
        ...,
        description=" ".join(
            [
                "The Unix timestamp (in seconds) of when the chat completion was created.",
                "Each chunk has the same timestamp.",
            ]
        ),
    )
    model: str = Field(..., description="The model to generate the completion.")
    system_fingerprint: str = Field(
        ..., description="This fingerprint represents the backend configuration that the model runs with."
    )
    object: str = Field("chat.completion.chunk", description="The object type, which is always chat.completion.chunk.")


class OpenAICompletionsChoice(BaseModel):
    """Text choice object from Completions endpoint."""

    text: str = Field(..., description="A chat completion delta generated by streamed model responses.")
    finish_reason: Optional[str] = Field(..., description="The reason the model stopped generating tokens.")
    index: int = Field(..., description="The index of the choice in the list of choices.")


class OpenAICompletionsResponse(BaseModel):
    """Response from Completions endpoint."""

    id: str = Field(..., description="A unique identifier for the chat completion. Each chunk has the same ID.")
    choices: list[OpenAICompletionsChoice] = Field(
        ..., description="A list of chat completion choices. Can be more than one if n is greater than 1."
    )
    created: int = Field(
        ...,
        description=" ".join(
            [
                "The Unix timestamp (in seconds) of when the chat completion was created.",
                "Each chunk has the same timestamp.",
            ]
        ),
    )
    model: str = Field(..., description="The model to generate the completion.")
    system_fingerprint: str = Field(
        ..., description="This fingerprint represents the backend configuration that the model runs with."
    )
    object: str = Field("text_completion", description="The object type, which is always chat.completion.chunk.")


############
# ADAPTERS #
############


class EmbeddingModelAdapter(ABC):
    """Abstract base class for embedding model adapters.

    Parameters
    ----------
    model_name : str
        Model name.

    endpoint_url : str, default=None
        Endpoint URL.
    """

    def __init__(self, *, model_name: str, endpoint_url: Optional[str] = None) -> None:
        self.model_name = model_name
        self.endpoint_url = endpoint_url

    @abstractmethod
    def embed_query(self, *, text: str, model_kwargs: Dict[str, Any]) -> EmbedQueryResponse:
        """Embed query.

        Parameters
        ----------
        text : str
            Input text to embed.

        model_kwargs : Dict[str, Any]
            Arguments to embedding model.

        Returns
        -------
        EmbedQueryResponse
            Embedding model response.
        """
        pass


class TextGenModelAdapter(ABC):
    """Abstract base class for text generation model adapters.

    Parameters
    ----------
    model_name : str
        Model name.

    endpoint_url : str, default=None
        Endpoint URL.
    """

    def __init__(self, *, model_name: str, endpoint_url: Optional[str] = None) -> None:
        self.model_name = model_name
        self.endpoint_url = endpoint_url

    @abstractmethod
    def generate(self, *, text: str, model_kwargs: Dict[str, Any]) -> GenerateResponse:
        """Text generation.

        Parameters
        ----------
        text : str
            Prompt input text.

        model_kwargs : Dict[str, Any]
            Arguments to text generation model.

        Returns
        -------
        GenerateResponse
            Text generation model response.
        """
        pass


class StreamTextGenModelAdapter(ABC):
    """Abstract base class for text generation model adapters with streaming option."""

    @abstractmethod
    def generate_stream(
        self,
        *,
        text: str,
        model_kwargs: Dict[str, Any],
    ) -> AsyncGenerator[GenerateStreamResponse, None]:
        """Text generation with token streaming.

        Parameters
        ----------
        text : str
            Prompt input text.

        model_kwargs : Dict[str, Any]
            Arguments to text generation model.

        Returns
        -------
        AsyncGenerator[GenerateStreamResponse, None]
            Text generation model response with streaming.
        """
        pass


def escape_curly_brackets(s: str) -> str:
    """Escapes curly brackets in the given string for downstream use with `str.format()`.

    Parameters
    ----------
    s : str
        String to be escaped.

    Returns
    -------
    str
        Escaped string.
    """
    return re.sub(r"({|})", r"\1\1", s)
