{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LISA-SDK\n",
    "In this notebook, we provide a tutorial of how to use the LISA SDK. LISA is an enabling service to easily deploy generative AI applications in AWS customer environments. LISA is an open-source infrastructure-as-code offering that is accessible via an API or simple user interface and provides scalable access to generative large language models and embedding language models. In order for the SDK to work properly you will need access to a deployed version of LISA and the REST API url for LISA-Serve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lisapy import LisaLlm\n",
    "from lisapy.authentication import get_cognito_token\n",
    "url = \"LISA-API-URL\"\n",
    "username = \"your cognito username\"\n",
    "client_id = \"Cognito client ID\"\n",
    "token = get_cognito_token(client_id=client_id, username=username)[\n",
    "    \"AuthenticationResult\"\n",
    "][\"IdToken\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to LISA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa = LisaLlm(\n",
    "    url=url,\n",
    "    verify=False,  # note only for dev deployments with self-signed certificates\n",
    "    timeout=60,\n",
    "    headers={\"Authorization\": f\"Bearer {token}\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get started by listing the actions that the API can perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lisa.list_models()\n",
    "display(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know what sorts of parameters are required for each of the action we can use the `describe_api` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa.describe_model(model_name=response[0].model_name, provider=response[0].provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different deployments of LISA may support different models. Let's see what models we have to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen_models = lisa.list_textgen_models()\n",
    "display(textgen_models)\n",
    "\n",
    "embedding_models = lisa.list_embedding_models()\n",
    "display(embedding_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation\n",
    "Now let's ask Lisa a question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lisa.describe_model(provider=\"ecs.textgen.tgi\", model_name=\"mistral-7b-instruct\")\n",
    "response = lisa.generate(\"What is Deep Learning?\",\n",
    "                         model=model,\n",
    "                         )\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's customize the model kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_kwargs.max_new_tokens = 10\n",
    "model.model_kwargs.streaming = False\n",
    "response = lisa.generate(\n",
    "    \"What is Deep Learning?\",\n",
    "    model=model,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "Now let's try streaming!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "model.model_kwargs.max_new_tokens = 512\n",
    "model.model_kwargs.streaming = True\n",
    "model.streaming = True\n",
    "for resp in lisa.generate_stream(prompt='\\n\\nUser:What is Deep Learning\\n\\nAssistant:', model=model):\n",
    "    sys.stdout.write(resp.token)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "LISA also serves embedding endpoints. Let's take those for a test drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model = lisa.describe_model(provider=\"ecs.embedding.tei\", model_name=\"bge-large-en-v1.5\")\n",
    "messages = [\"Deep learning is awesome\", \"Deep learning is vaporware\", \"Baseball is fun\"]\n",
    "embeddings = lisa.embed(messages, model=model)\n",
    "print(f\"\"\"\n",
    "The similarity between:\n",
    "\n",
    "      {messages[0]}\n",
    "\n",
    "  and\n",
    "\n",
    "      {messages[1]}\n",
    "\n",
    "is {np.dot(embeddings[0], embeddings[1])}\n",
    "\n",
    "The similarity between\n",
    "\n",
    "      {messages[0]}\n",
    "\n",
    "  and\n",
    "\n",
    "      {messages[2]}\n",
    "\n",
    "is {np.dot(embeddings[0], embeddings[2])}\n",
    "      \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to end LangChain example based on [this example](https://python.langchain.com/docs/expression_language/cookbook/retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS # may require pip install faiss-gpu\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# from langchain_community.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "from lisapy.langchain import LisaTextgen\n",
    "from lisapy.langchain import LisaEmbeddings\n",
    "from lisapy.authentication import get_cognito_token\n",
    "\n",
    "url = \"LISA-API-URL\"\n",
    "username = \"your cognito username\"\n",
    "client_id = \"Cognito client ID\"\n",
    "token = get_cognito_token(client_id=client_id, username=username)[\n",
    "    \"AuthenticationResult\"\n",
    "][\"IdToken\"]\n",
    "\n",
    "lisa = LisaLlm(\n",
    "    url=url, verify=False, timeout=60, headers={\"Authorization\": f\"Bearer {token}\"}\n",
    ")\n",
    "\n",
    "embedding = LisaEmbeddings(\n",
    "    provider=\"ecs.embedding.tei\", model_name=\"bge-large-en-v1.5\", client=lisa\n",
    ")\n",
    "llm = LisaTextgen(\n",
    "    model_name=\"mistral-7b-instruct\",\n",
    "    provider=\"ecs.textgen.tgi\",\n",
    "    client=lisa,\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_texts([\"harrison worked at kensho\"], embedding=embedding)\n",
    "\n",
    "# could also leverage opensearch for vector store\n",
    "# vector_search = OpenSearchVectorSearch(\n",
    "#     <OpenSearch URI>,\n",
    "#     \"embeddings\",\n",
    "#     embedding\n",
    "# )\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "chain.invoke(\"where did harrison work?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lisa-sdk-Zw_Ddf8y-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
